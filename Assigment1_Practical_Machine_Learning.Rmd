---
title: "M8 Proj - Prac Machine Learning"
author: "Freddy Loo"
date: "2 December 2015"
output: html_document
---

###Executive Summary
This paper is to analyse how well exercise (barbell lifts) is being performed by the participants, using data from the fitness devices. 
The outcome of the model would be the "classe" variable


###1. Data Preparation
1. Downloading the source files. Ensure that the "#DIV/0!" string is converted to na
2. Set the seed to ensure reproducebility.
```{r echo=TRUE, results=FALSE}
library(caret)
library(rattle)
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv","training.csv")

download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv","testing.csv")

traindata<-read.csv("training.csv",na.strings=c("#DIV/0!"))
testdata<-read.csv("testing.csv",na.strings=c("#DIV/0!"))
set.seed("97531")
```


### 2. Preprocessing
1. Checking and remove low variability columns using nearZeroVar function for both test and train data.
2. Remove columns with >90% NA or "" values
3. Remove the unnecessary columns - user_name, raw_timestamp_part_1, raw_timestamp_part_2, cvtd_timestamp,num_window
3. Split the train data to do cross validation on a 75/25 ratio for cross vaidation

```{r echo=FALSE}
nzv<-nearZeroVar(traindata)
traindataPr<-traindata[,-nzv] 
testdataPr<-testdata[,-nzv]

#remove columns > 90% empty
limit<-dim(traindata)[1]*0.9
badcolumnInd<-apply(traindataPr,2, function(x)sum(is.na(x))>limit || sum(x=="")>limit)
traindataPr<-traindataPr[,!badcolumnInd] 
testdataPr<-testdataPr[,!badcolumnInd]

#remove unnnessary columns
traindataPr<-traindataPr[,-c(1,2,3,4,5,6)] 
testdataPr<-testdataPr[,-c(1,2,3,4,5,6)]

#cross validation data
cvDataInd <-createDataPartition(y=traindataPr$classe, p=0.75, list=FALSE)
cvdata<- traindataPr[-cvDataInd,]
traindataPr<- traindataPr[cvDataInd,]
```

### 3. Model Building
1. Test the model with 3 methods, glm, random forest and lda
2. Test the different model using ConfusionMatrix

```{r echo=FALSE, cache=TRUE, results=FALSE}
modfitrf<- train(classe~.,data=traindataPr, method="rf")
modfitlda<- train(classe~.,data=traindataPr, method="lda")
modfitrpart<- train(classe~.,data=traindataPr, method="rpart")

fancyRpartPlot(modfitrpart$finalModel)
```

#### Random Forest
```{r echo=FALSE, cache=TRUE, results=FALSE}
predrf<-predict(modfitrf,cvdata)
confusionMatrix(predrf,cvdata$classe)
```

#### Linear Discriminant Analysis (LDA)
```{r echo=FALSE, cache=TRUE, results=FALSE}
predlda<-predict(modfitlda,cvdata)
confusionMatrix(predlda,cvdata$classe)
```

#### Classification Tree
```{r echo=FALSE, cache=TRUE, results=FALSE}
predrpart<-predict(modfitrpart,cvdata)
confusionMatrix(predrpart,cvdata$classe)
```


### Test the model using the Test Set
1. Based on the accuracy level, the selected model is Random Forest with 99.02% accuracy
2. Testing the model using the test data
```{r echo=FALSE}
predtest<-predict(modfitrf,testdataPr)
predtest
```


